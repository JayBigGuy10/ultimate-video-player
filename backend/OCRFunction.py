import pytesseract
import cv2
from datetime import datetime
import threading
import string

pytesseract.pytesseract.tesseract_cmd = r"BackendEnv\tesseract\tesseract.exe"

#convert seconds to hour:minute:seconds
def format_time(seconds):
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = seconds % 60
        return f"{hours:02}:{minutes:02}:{secs:06.3f}"

#get the text from a given frame, and store it in the results array at the given index
def process_frame(frame, index, results):
    #get text
    imgchar = pytesseract.image_to_string(frame)

    #remove weird charecters
    imgchar = ''.join(filter(lambda x: x in set(string.printable), imgchar))

    #remove double line breaks
    imgchar	= imgchar.strip().replace('\n\n','\n')

    #store the cleaned up string into the array of results
    results[index] = imgchar

def OCRFunction(filePath, id):

    print("OCR Running")

    #Open the video with the given file path
    cap =cv2.VideoCapture(filePath)

    #fps = cap.get(cv2.CAP_PROP_FPS)

    #Raise issue if we were not able to open the video
    if not cap.isOpened():
        raise IOError("Cannot open video")

    #track which frame of video we are on
    counter= 0

    #array to store the lines of text into
    results = [""]

    #array to hold each running thread
    threads=[]

    while True:
        #get a frame of video
        ret,frame=cap.read()
        
        counter +=1

        # process the text for 1 in every 30 frames (i.e 1 per second)
        if ((counter%30)==0): 

            #Make a space in the results array
            results.append("")

            #Process the frame in a new thread
            thread = threading.Thread(target=process_frame, args=(frame, int(counter/30), results))
            threads.append(thread)
            thread.start()
            
        if ret == False: # breaks loop when video ends
            break

    #wait for all of the frames to finish processing
    for thread in threads:
        thread.join()

    #Write the header of the text file
    f = open("static/video/"+str(id)+"OCR.vtt", "w")
    f.write("WEBVTT\n\nNOTE Generated by OCRFunction "+datetime.now().strftime("%m/%d/%Y, %H:%M:%S")+"\n")

    
    filtered_results = []
    prev_index = 0

    # For each line of text
    for i, imgchar in enumerate(results):
        if i > 1:
            #check if the current text is different from the previous text (ignores capitalisation, spaces, and line breaks changing)
            if imgchar.lower().replace('\n','').replace(' ','') != results[i-1].lower().replace('\n','').replace(' ',''):
                #current line is different, so previous line is the end of some text on screen
                #add the previous line to results (with where it started from, to where it ended)
                filtered_results.append([results[i-1], prev_index, i])

                #since text has changed, we are at the start of a new block. Keep track of the new blocks start in prev_index
                prev_index = i

    #for each of the unique lines of text
    for result in filtered_results:
        #write it out to the file in WebVTT format
        imgchar = result[0]
        print("'"+imgchar+"'") # prints value to command line so i can see while debugging
        f.write("\n\n"+str(format_time(result[1]))+ " --> " + str(format_time(result[2]))+"\n"+imgchar)# writes line to text

    #save the file
    f.close()

    #tidy up the video processing libraries
    cap.release()
    cv2.destroyAllWindows()

if __name__ == "__main__":
    inputPath = """static/video/2.mp4"""
    print("Running OCR Function")
    OCRFunction(inputPath,1)
